{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El primer gran proyecto: ¡Profesionalmente Tú!\n",
    "\n",
    "### Y, uso de la herramienta.\n",
    "\n",
    "### Pero primero: presentamos Pushover\n",
    "\n",
    "Pushover es una herramienta práctica para enviar notificaciones push a tu teléfono.\n",
    "\n",
    "¡Es facilísima de configurar e instalar!\n",
    "\n",
    "Simplemente visita https://pushover.net/, crea una cuenta gratuita y genera tus claves API.\n",
    "\n",
    "Como señaló el estudiante Ron (¡gracias, Ron!), hay dos tokens que se pueden crear en Pushover:\n",
    "1. El token de usuario, que se obtiene en la página principal de Pushover.\n",
    "2. El token de aplicación, que se obtiene al ir a https://pushover.net/apps/build y crear una aplicación.\n",
    "\n",
    "(Esto te permite organizar tus notificaciones push en diferentes aplicaciones en el futuro).\n",
    "\n",
    "Agrega a tu archivo `.env`:\n",
    "```\n",
    "PUSHOVER_USER=pon_tu_token_de_usuario_aquí\n",
    "PUSHOVER_TOKEN=pon_tu_token_de_aplicación_aquí\n",
    "```\n",
    "\n",
    "E instala la aplicación Pushover en tu teléfono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dzhdo\\Documents\\PROYECTOS_JUNY\\AI_agents\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El inicio usual\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para pushover\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    requests.post(pushover_url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: HOLA!!\n"
     ]
    }
   ],
   "source": [
    "push(\"HOLA!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name=\"Nombre no proporcionado\", notes=\"not provided\"):\n",
    "    push(f\"Registrando interés de {name} con email {email} y notas {notes}\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    push(f\"Registrando pregunta no respondida: {question}\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Utilice esta herramienta para registrar que un usuario está interesado en estar en contacto y proporcionó una dirección de correo electrónico.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La dirección de correo electrónico de este usuario\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"El nombre del usuario, si lo proporcionó\"\n",
    "            }\n",
    "            ,\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Cualquier información adicional sobre la conversación que merezca ser registrada para dar contexto\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Siempre use esta herramienta para registrar cualquier pregunta que no se pueda responder, ya que no sabía la respuesta\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La pregunta que no se pudo responder\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'record_user_details',\n",
       "   'description': 'Utilice esta herramienta para registrar que un usuario está interesado en estar en contacto y proporcionó una dirección de correo electrónico.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'email': {'type': 'string',\n",
       "      'description': 'La dirección de correo electrónico de este usuario'},\n",
       "     'name': {'type': 'string',\n",
       "      'description': 'El nombre del usuario, si lo proporcionó'},\n",
       "     'notes': {'type': 'string',\n",
       "      'description': 'Cualquier información adicional sobre la conversación que merezca ser registrada para dar contexto'}},\n",
       "    'required': ['email'],\n",
       "    'additionalProperties': False}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'record_unknown_question',\n",
       "   'description': 'Siempre use esta herramienta para registrar cualquier pregunta que no se pueda responder, ya que no sabía la respuesta',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'question': {'type': 'string',\n",
       "      'description': 'La pregunta que no se pudo responder'}},\n",
       "    'required': ['question'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función puede tomar una lista de llamadas a herramientas y ejecutarlas. ¡Este es el IF statement!!\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Herramienta llamada: {tool_name}\", flush=True)\n",
    "\n",
    "        # ¡EL GRAN IF !!!\n",
    "\n",
    "        if tool_name == \"record_user_details\":\n",
    "            result = record_user_details(**arguments)\n",
    "        elif tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**arguments)\n",
    "\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Registrando pregunta no respondida: esta es una pregunta realmente difícil\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recorded': 'ok'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"record_unknown_question\"](\"esta es una pregunta realmente difícil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta es una forma más elegante de evitar el IF statement.\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Herramienta llamada: {tool_name}\", flush=True)\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = PdfReader(\"me/linkedin.pdf\")\n",
    "# linkedin = \"\"\n",
    "# for page in reader.pages:\n",
    "#     text = page.extract_text()\n",
    "#     if text:\n",
    "#         linkedin += text\n",
    "\n",
    "with open(\"me/Resumen.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Dzhuneyt Myumyunov Saliev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = f\"\"\"Estás actuando como {name}. Estás respondiendo preguntas en el sitio web de {name}, en particular preguntas relacionadas con la carrera, los antecedentes, las habilidades y la experiencia de {name}.\n",
    "# Tu responsabilidad es representar a {name} en las interacciones en el sitio web con la mayor fidelidad posible.\n",
    "# Se te proporciona un resumen de los antecedentes y el perfil de LinkedIn de {name} que puedes usar para responder preguntas.\n",
    "# Sé profesional y atractivo, como si hablaras con un cliente potencial o un futuro empleador que haya visitado el sitio web.\n",
    "# Si no sabes la respuesta a alguna pregunta, usa la herramienta record_unknown_question para registrar la pregunta que no pudiste responder, incluso si se trata de algo trivial o no relacionado con tu carrera.\n",
    "# Si el usuario participa en una conversación, intenta que se ponga en contacto por correo electrónico; pídele su correo electrónico y regístralo con la herramienta record_user_details.\"\"\"\n",
    "\n",
    "# system_prompt += f\"\\n\\n## Resumen:\\n{summary}\\n\\n## LinkedIn Perfil:\\n{linkedin}\\n\\n\"\n",
    "# system_prompt += f\"En este contexto, chatea con el usuario, siempre con el personaje {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Estás actuando como {name}. Estás respondiendo preguntas en el sitio web de {name}, en particular preguntas relacionadas con la carrera, los antecedentes, las habilidades y la experiencia de {name}.\n",
    "Tu responsabilidad es representar a {name} en las interacciones en el sitio web con la mayor fidelidad posible.\n",
    "Se te proporciona los detalles del perfil de LinkedIn de {name} que puedes usar para responder preguntas.\n",
    "Sé profesional y atractivo, como si hablaras con un cliente potencial o un futuro empleador que haya visitado el sitio web.\n",
    "Si no sabes la respuesta a alguna pregunta, usa la herramienta record_unknown_question para registrar la pregunta que no pudiste responder, incluso si se trata de algo trivial o no relacionado con tu carrera.\n",
    "Si el usuario participa en una conversación, intenta que se ponga en contacto por correo electrónico; pídele su correo electrónico y regístralo con la herramienta record_user_details.\"\"\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Resumen:\\n{summary}\\n\\n\"\n",
    "system_prompt += f\"En este contexto, chatea con el usuario, siempre con el personaje {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # Esta es la llamada a la LLM - nota que pasamos el json de las herramientas\n",
    "\n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, tools=tools)\n",
    "\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        # Si la LLM quiere llamar a una herramienta, la llamamos!\n",
    "         \n",
    "        if finish_reason==\"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = message.tool_calls\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            messages.append(message)\n",
    "            messages.extend(results)\n",
    "        else:\n",
    "            done = True\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y ahora, la implementación\n",
    "\n",
    "Este código está en `app.py`\n",
    "\n",
    "La implementación se realizará en HuggingFace Spaces. Gracias, estudiante Robert M, por mejorar estas instrucciones.\n",
    "\n",
    "Antes de empezar: recuerda actualizar los archivos del directorio \"me\" (tu perfil de LinkedIn y summary.txt) para que se muestren tus credenciales.\n",
    "\n",
    "Comprueba también que no haya ningún archivo README en el directorio 1_foundations. Si lo hay, elimínalo. El proceso de implementación crea un nuevo archivo README en este directorio.\n",
    "\n",
    "1. Visita https://huggingface.co y crea una cuenta.\n",
    "2. En el menú Avatar, en la esquina superior derecha, selecciona \"Tokens de acceso\". Selecciona \"Crear nuevo token\". Asígnale permisos de escritura.\n",
    "3. Tome este token y agréguelo a su archivo .env: `HF_TOKEN=hf_xxx`. Si no se detecta durante la implementación, consulte la nota a continuación.\n",
    "4. Desde la carpeta 1_foundations, introduzca `uv run gradio deploy`. Si por alguna razón aún le solicita que introduzca su token HF, interrúmpalo con Ctrl+C y ejecute `uv run dotenv -f ../.env run -- uv run gradio deploy`, lo que obliga a que todas sus claves se configuren como variables de entorno.\n",
    "5. Siga sus instrucciones: asígnele el nombre \"career_conversation\", especifique app.py, elija cpu-basic como hardware, confirme que es necesario proporcionar secretos, proporcione su clave de API de OpenAI, su usuario y token de Pushover, y confirme que no se permiten las acciones de GitHub. Nota adicional sobre el token HuggingFace\n",
    "\n",
    "Un par de estudiantes han mencionado que HuggingFace no detecta su token, a pesar de estar en el archivo .env. Prueba lo siguiente:\n",
    "1. Reinicia el cursor.\n",
    "2. Vuelve a ejecutar load_dotenv(override=True) y usa una nueva terminal (el botón + en la esquina superior derecha de la terminal).\n",
    "3. En la terminal, ejecuta esto antes de la implementación de gradio: `$env:HF_TOKEN = \"hf_XXXX\"`.\n",
    "Gracias, James y Martins, por estos consejos.\n",
    "\n",
    "#### Más información sobre estos secretos:\n",
    "\n",
    "Si no entiendes qué sucede con estos secretos, solo te pide que introduzcas el nombre y el valor de la clave para cada uno de ellos. Por ejemplo, escribirías:\n",
    "`OPENAI_API_KEY`\n",
    "Seguido de:\n",
    "`sk-proj-...`\n",
    "\n",
    "Si no quieres configurar los secretos de esta manera o si algo sale mal, no hay problema: puedes cambiarlos más tarde:\n",
    "\n",
    "1. Inicia sesión en el sitio web de HuggingFace.\n",
    "2. Ve a tu perfil a través del menú \"Avatar\" en la esquina superior derecha.\n",
    "3. Selecciona el espacio que has implementado.\n",
    "4. Haz clic en la rueda de Ajustes en la esquina superior derecha.\n",
    "5. Puedes desplazarte hacia abajo para cambiar tus secretos, eliminar el espacio, etc.\n",
    "\n",
    "#### ¡Y ya deberías estar implementado!\n",
    "\n",
    "Aquí está el mío: https://huggingface.co/spaces/ed-donner/Career_Conversation\n",
    "\n",
    "Acabo de recibir una notificación push de que un estudiante me preguntó cómo puede convertirse en presidente de su país. 😂😂\n",
    "\n",
    "Para más información sobre la implementación:\n",
    "\n",
    "https://www.gradio.app/guides/sharing-your-app#hosting-on-hf-spaces\n",
    "\n",
    "Para eliminar tu espacio en el futuro:\n",
    "\n",
    "1. Inicia sesión en HuggingFace.\n",
    "2. En el menú Avatar, selecciona tu perfil.\n",
    "3. Haz clic en el espacio y selecciona la rueda de configuración en la esquina superior derecha.\n",
    "4. Desplázate hasta la sección Eliminar en la parte inferior.\n",
    "5. ADEMÁS: borra el archivo README que Gradio haya creado dentro de la carpeta 1_foundations (de lo contrario, no te hará las preguntas la próxima vez que implementes Gradio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Ejercicio</h2>\n",
    "            <span style=\"color:#ff7800;\">• Ante todo, ¡impleméntalo tú mismo! Es una herramienta real y valiosa: el futuro currículum.<br/>\n",
    "• A continuación, mejora los recursos: añade un mejor contexto sobre ti. Si conoces RAG, añade una base de conocimientos sobre ti.<br/>\n",
    "• ¡Añade más herramientas! Podrías tener una base de datos SQL con preguntas y respuestas comunes que el LLM pueda leer y escribir.<br/>\n",
    "• Incorpora al Evaluador del último laboratorio y añade otros patrones de Agentic.\n",
    "</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Implicaciones Comerciales</h2>\n",
    "            <span style=\"color:#00bfff;\">Aparte de lo obvio (tu alter ego profesional), esto tiene aplicaciones comerciales en cualquier situación en la que necesites un asistente de IA con experiencia en el dominio y capacidad para interactuar con el mundo real.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
