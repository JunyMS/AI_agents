{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Bienvenido de nuevo a los cuadernos de Python!\n",
    "\n",
    "¿Me extrañabas?\n",
    "\n",
    "### Y bienvenido a la Semana 4, Día 2 - ¡Presentación de Langgraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunas constantes útiles\n",
    "\n",
    "nouns = [\"Coles\", \"Unicornios\", \"Tostadora\", \"Pinguinos\", \"Bananas\", \"Zombies\", \"Arcoiris\", \"Anguilas\", \"Pepinillos\", \"Muffins\"]\n",
    "adjectives = [\"malo\", \"pedante\", \"existencial\", \"malhumorado\", \"brillante\", \"desconfiado\", \"sarcástico\", \"molloso\", \"misterioso\"]\n",
    "\n",
    "# Algunas funciones útiles\n",
    "\n",
    "def get_random_noun():\n",
    "    return random.choice(nouns)\n",
    "\n",
    "def get_random_adjective():\n",
    "    return random.choice(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestro primer paso favorito! Crew lo hacía por nosotros, por cierto.\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text: Annotated[str, \"algo para gritar\"]) -> str:\n",
    "    print(text.upper())\n",
    "    return text.upper()\n",
    "\n",
    "shout(\"hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una palabra sobre \"anotado\"\n",
    "\n",
    "Probablemente sepas esto; Tipo de insinción es una característica en Python que le permite especificar el tipo de algo:\n",
    "\n",
    "`my_favorite_things: list`\n",
    "\n",
    "Pero es posible que no sepas esto:\n",
    "\n",
    "También puede usar algo llamado \"anotado\" para agregar información adicional que alguien más podría encontrar útil:\n",
    "\n",
    "`my_favorite_things: anotado [lista,\" estos son algunos de los míos \"]`\n",
    "\n",
    "Langgraph necesita que usemos esta función cuando definimos nuestro objeto de estado.\n",
    "\n",
    "Quiere que le digamos qué función debe llamar para actualizar el estado con un nuevo valor.\n",
    "\n",
    "Esta función se llama **reductor**.\n",
    "\n",
    "Langgraph proporciona un reductor predeterminado llamado `add_messages` que se encarga del caso más común.\n",
    "\n",
    "Y con suerte explica por qué el estado se ve así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Definir el objeto de estado\n",
    "\n",
    "Puedes usar cualquier objeto Python; Pero es más común usar un tipEddict o un basemodelo pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(BaseModel):\n",
    "        \n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Iniciar el Graph Builder con esta clase State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Crear un nodo\n",
    "\n",
    "Un nodo puede ser cualquier función de Python.\n",
    "\n",
    "El reductor que establecemos antes se llama automáticamente para combinar esta respuesta con respuestas anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_first_node(old_state: State) -> State:\n",
    "\n",
    "    reply = f\"{random.choice(nouns)} son {random.choice(adjectives)}\"\n",
    "    messages = [{\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "    new_state = State(messages=messages)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"first_node\", our_first_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Creamos las aristas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Compilamos el Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listo! El momento de la verdad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por cierto, ¡por qué te mostré eso?\n",
    "\n",
    "Para señalar que Langgraph se trata de funciones de Python, ¡no necesita involucrar a LLM!\n",
    "\n",
    "Ahora volveremos a hacer los 5 pasos, pero en 1 disparo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Define el objeto de estado\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Iniciar el Graph Builder con esta clase State\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Crear un nodo\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(old_state: State) -> State:\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Crear aristas\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Compilar el Grafo\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Y esto es todo! Hagamos esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
