{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semana 5, Día 4\n",
    "\n",
    "## AutoGen Core - Distribuido\n",
    "\n",
    "¡Solo os daré un adelanto!\n",
    "\n",
    "En parte porque no estoy seguro de su relevancia. Si deseas que agregue más contenido, por favor, házmelo saber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "ALL_IN_ONE_WORKER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comienza con nuestra clase de Mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora: un host para nuestro entorno de ejecución distribuido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a reintroducir una herramienta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Útil para cuando necesitas buscar en Internet.\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"Para ayudar con una decisión sobre si usar AutoGen en un nuevo proyecto de Agentes de IA, \\\n",
    "por favor investiga y responde brevemente con razones a favor de elegir AutoGen; los pros de AutoGen.\"\n",
    "\n",
    "instruction2 = \"Para ayudar con una decisión sobre si usar AutoGen en un nuevo proyecto de Agentes de IA, \\\n",
    "por favor investiga y responde brevemente con razones en contra de elegir AutoGen; los contras de Autogen.\"\n",
    "\n",
    "judge = \"Debes tomar una decisión sobre si usar AutoGen para un proyecto. \\\n",
    "Tu equipo de investigación ha llegado a las siguientes razones a favor y en contra. \\\n",
    "Basado puramente en la investigación de tu equipo, por favor responde con tu decisión y una breve justificación.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y hacer algunos Agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros de AutoGen:\\n{response1.content}\\n\\n## Cons de AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Responde con tu decisión y una breve justificación\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decisión:\\n\\n\" + response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "\n",
    "if ALL_IN_ONE_WORKER:\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else:\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await worker.send_message(Message(content=\"¡Empezamos!\"), agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros de AutoGen:\n",
       "Aquí tienes algunas razones a favor de usar AutoGen en proyectos de Agentes de IA:\n",
       "\n",
       "1. **Facilidad de uso**: AutoGen ofrece un marco fácil de usar que permite a los desarrolladores implementar agentes de forma eficiente sin complicaciones innecesarias.\n",
       "\n",
       "2. **Capacidades avanzadas**: Es ideal para la automatización compleja y entornos dinámicos, lo que permite a los agentes gestionar tareas diversas y ajustarse a diferentes escenarios de trabajo.\n",
       "\n",
       "3. **Alta personalización**: Los usuarios pueden personalizar los agentes con un control detallado sobre sus componentes y flujos de trabajo, adaptándolos a necesidades específicas del proyecto.\n",
       "\n",
       "4. **Escalabilidad**: Su arquitectura escalable permite la integración de múltiples agentes, cada uno con roles y capacidades específicos, fomentando la colaboración y mejorando la resolución de problemas.\n",
       "\n",
       "5. **Integración con múltiples herramientas**: AutoGen permite la integración con diversos modelos de lenguaje y herramientas, lo que amplía sus aplicaciones y capacidades.\n",
       "\n",
       "Estas ventajas hacen de AutoGen una opción fuerte para proyectos que requieren implementación de Agentes de IA.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "## Cons de AutoGen:\n",
       "Aquí tienes algunas desventajas de usar AutoGen para un nuevo proyecto de Agentes de IA:\n",
       "\n",
       "1. **Capacidades de IA Limitadas**: AutoGen puede no ser la mejor opción para tareas de automatización complejas que requieren un alto nivel de inteligencia artificial, limitando su aplicabilidad en escenarios más avanzados.\n",
       "\n",
       "2. **Menos Personalizable**: Aunque permite cierto grado de personalización, puede haber limitaciones en comparación con otros frameworks que ofrecen más flexibilidad en la integración y configuración de diversos componentes.\n",
       "\n",
       "3. **Dependencia de API**: El uso de AutoGen normalmente requiere claves de API para su integración con modelos de lenguaje, lo que puede incorporar costos adicionales y complicar la gestión de acceso y autorización.\n",
       "\n",
       "4. **Curva de Aprendizaje**: La utilización de AutoGen puede requerir que el equipo de desarrollo aprenda a manejar nuevas herramientas y paradigmas, lo que podría ralentizar el progreso inicial del proyecto.\n",
       "\n",
       "5. **Menos soporte en la automatización entre agentes**: Si bien soporta un rango de tipos de agentes, puede ser menos eficaz en facilitar interacciones complejas entre estos, limitando su utilidad en proyectos que requieren un alto grado de colaboración entre agentes.\n",
       "\n",
       "Considerar estas desventajas te ayudará a tomar una decisión informada sobre el uso de AutoGen en tu proyecto. \n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "\n",
       "## Decisión:\n",
       "\n",
       "Después de analizar los pros y los contras de AutoGen, mi decisión es **utilizar AutoGen para el proyecto de Agentes de IA**.\n",
       "\n",
       "Justificación: A pesar de las preocupaciones sobre las capacidades de IA limitadas y la curva de aprendizaje, las ventajas de facilidad de uso, capacidades avanzadas y alta personalización pesan considerablemente. La escalabilidad de AutoGen y su capacidad para integrarse con múltiples herramientas lo convierten en una opción robusta para entornos dinámicos donde la eficiencia en la implementación y la adaptabilidad son esenciales. Además, su capacidad para manejar tareas diversas puede ser muy valiosa en este proyecto. Las desventajas pueden ser gestionadas con un enfoque estratégico de desarrollo y formación del equipo. \n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "await host.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
