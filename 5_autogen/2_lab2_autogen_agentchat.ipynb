{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semana 5 Día 2\n",
    "\n",
    "### AutoGen AgentChat - Profundizando...\n",
    "\n",
    "1. Conversación multimodal\n",
    "2. Salidas estructuradas\n",
    "3. Uso de herramientas LangChain\n",
    "4. Equipos\n",
    "\n",
    "...y una sorpresa especial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from IPython.display import display, Markdown\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una conversación multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://edwarddonner.com/wp-content/uploads/2024/10/from-software-engineer-to-AI-DS.jpeg\"\n",
    "\n",
    "pil_image = Image.open(BytesIO(requests.get(url).content))\n",
    "img = AGImage(pil_image)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_modal_message = MultiModalMessage(content=[\"Describe el contenido de esta imagen en detalle\", img],\n",
    "                                         source=\"User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "\n",
    "describer = AssistantAgent(\n",
    "    name=\"description_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Eres bueno describiendo imágenes\",\n",
    ")\n",
    "\n",
    "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
    "reply = response.chat_message.content\n",
    "display(Markdown(reply))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salidas Estructuradas!\n",
    "\n",
    "Autogen AgentChat hace que sea muy sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    scene: str = Field(description=\"Brevemente, el escenario general de la imagen\")\n",
    "    message: str = Field(description=\"El punto que la imagen está tratando de transmitir\")\n",
    "    style: str = Field(description=\"El estilo artístico de la imagen\")\n",
    "    orientation: Literal[\"portrait\", \"landscape\", \"square\"] = Field(description=\"La orientación de la imagen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "\n",
    "describer = AssistantAgent(\n",
    "    name=\"description_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Eres bueno describiendo imágenes en detalle\",\n",
    "    output_content_type=ImageDescription,\n",
    ")\n",
    "\n",
    "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
    "reply = response.chat_message.content\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "print(f\"Escenario:\\n{textwrap.fill(reply.scene)}\\n\\n\")\n",
    "print(f\"Mensaje:\\n{textwrap.fill(reply.message)}\\n\\n\")\n",
    "print(f\"Estilo:\\n{textwrap.fill(reply.style)}\\n\\n\")\n",
    "print(f\"Orientación:\\n{textwrap.fill(reply.orientation)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando las herramientas de LangChain desde AutoGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoGen's wrapper:\n",
    "\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "\n",
    "# LangChain tools:\n",
    "\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from langchain.agents import Tool\n",
    "\n",
    "\n",
    "prompt = \"\"\"Tu tarea es encontrar un vuelo directo de ida de JFK a LHR en junio de 2025.\n",
    "Primero, busca en línea ofertas atractivas.\n",
    "Después, anota todas las ofertas en un archivo llamado flights.md con todos los detalles.\n",
    "Finalmente, selecciona la que consideres mejor y responde con un breve resumen.\n",
    "Responde solo con el vuelo seleccionado, y solo después de haber escrito los detalles en el archivo.\"\"\"\n",
    "\n",
    "\n",
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Útil para cuando necesitas buscar en Internet.\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)\n",
    "autogen_tools = [autogen_serper]\n",
    "\n",
    "langchain_file_management_tools = FileManagementToolkit(root_dir=\"sandbox\").get_tools()\n",
    "for tool in langchain_file_management_tools:\n",
    "    autogen_tools.append(LangChainToolAdapter(tool))\n",
    "\n",
    "for tool in autogen_tools:\n",
    "    print(tool.name, tool.description)\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "agent = AssistantAgent(name=\"searcher\", model_client=model_client, tools=autogen_tools, reflect_on_tool_use=True)\n",
    "message = TextMessage(content=prompt, source=\"user\")\n",
    "result = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "for message in result.inner_messages:\n",
    "    print(message.content)\n",
    "display(Markdown(result.chat_message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora necesitamos llamar nuevamente al agente para escribir el archivo.\n",
    "\n",
    "message = TextMessage(content=\"OK procedemos\", source=\"user\")\n",
    "\n",
    "result = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "for message in result.inner_messages:\n",
    "    print(message.content)\n",
    "display(Markdown(result.chat_message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacciones con el Equipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import  TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "\n",
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Útil para cuando necesitas buscar en Internet.\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "prompt = \"\"\"Busca un vuelo directo de ida de JFK a LHR en junio de 2025.\"\"\"\n",
    "\n",
    "\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    tools=[autogen_serper],\n",
    "    system_message=\"Eres un asistente de IA que busca ofertas prometedoras en vuelos. Incorpora cualquier retroalimentación que recibas.\",\n",
    ")\n",
    "\n",
    "evaluation_agent = AssistantAgent(\n",
    "    \"evaluator\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Proporciona retroalimentación constructiva. Responde con 'APROBAR' cuando tu retroalimentación sea abordada.\",\n",
    ")\n",
    "\n",
    "text_termination = TextMentionTermination(\"APROBAR\")\n",
    "\n",
    "# Gracias a Peter A por agregar el max_turns - de lo contrario, esto podría entrar en un bucle..\n",
    "\n",
    "team = RoundRobinGroupChat([primary_agent, evaluation_agent], termination_condition=text_termination, max_turns=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await team.run(task=prompt)\n",
    "for message in result.messages:\n",
    "    print(f\"{message.source}:\\n{message.content}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redoble..\n",
    "\n",
    "## Introducimos el MCP!\n",
    "\n",
    "Nuestro primer vistazo al Protocolo de Contexto de Modelo de Anthropic:\n",
    "\n",
    "Autogen facilita el uso de herramientas MCP, al igual que las herramientas LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Un momento, un problema considerable para los usuarios de PC con Windows</h2>\n",
    "<span style=\"color:#ff7800;\">Tengo malas noticias. Hay un problema al ejecutar servidores MCP en PC con Windows; Mac y Linux funcionan correctamente. Este problema se conoce desde el 4 de mayo de 2025. Le pedí a o3 de Deep Research que buscara soluciones alternativas; <a href=\"https://chatgpt.com/share/6817bbc3-3d0c-8012-9b51-631842470628\">confirmaron el problema</a> y la solución alternativa.<br/><br/>\n",
    "La solución alternativa es un poco aburrida. Se trata de aprovechar \"WSL\", el enfoque de Microsoft para ejecutar Linux en tu PC. ¡Tendrás que seguir más instrucciones de configuración! Pero es rápido, y varios estudiantes han confirmado que les funciona a la perfección. Entonces, este laboratorio y los laboratorios MCP de la semana 6 funcionan. Además, WSL es una excelente manera de desarrollar software en tu PC con Windows. También puedes omitir esta última celda, pero tendrás que volver a ella al comenzar la semana 6.<br/>\n",
    "Las instrucciones de configuración de WSL se encuentran en la carpeta Setup, <a href=\"../setup/SETUP-WSL.md\">en el archivo llamado SETUP-WSL.md</a>. Espero que esto solo te retrase un poco; deberías estar listo para usar pronto. ¡Qué alegría trabajar con tecnología de vanguardia!<br/><br/>\n",
    "Muchas gracias al estudiante Kaushik R. por mencionar que esto es necesario aquí, así como en la semana 6. ¡Gracias, Kaushik!\n",
    "</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n",
    "\n",
    "# Obtenemos la herramienta fetch desde mcp-server-fetch.\n",
    "fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])\n",
    "fetcher = await mcp_server_tools(fetch_mcp_server)\n",
    "\n",
    "# Creamos un agente que puede usar la herramienta fetch.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=fetcher, reflect_on_tool_use=True)  # type: ignore\n",
    "\n",
    "# Hacemos que el agente busque el contenido de una URL y lo resuma.\n",
    "result = await agent.run(task=\"Revisa cursos.frogamesformacion.com y resume lo que aprendes. Responde en Markdown.\")\n",
    "display(Markdown(result.messages[-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
